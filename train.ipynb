{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders = []\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create(2, 2, 7, 7)\n",
    "classifier = cv2.CascadeClassifier()\n",
    "classifier.load(\"utils/lbpcascade_frontalface.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face Detected:  1LM.jpg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 11.58.10.jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 11.58.09 (2).jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 11.58.05.jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 11.58.05 (3).jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 11.58.02 (1).jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 11.58.08 (2).jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 11.58.09 (1).jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 11.58.04 (1).jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 11.58.07 (1).jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 11.58.08 (1).jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 11.58.05 (2).jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 11.58.09.jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 11.58.05 (1).jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 11.58.07 (2).jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 11.58.06 (1).jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 11.58.06.jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 11.58.04.jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 11.58.08.jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 11.58.09 (3).jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 13.24.20.jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 13.25.02.jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 13.23.58.jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 13.23.54.jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 13.24.07.jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 13.25.33.jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 13.24.45.jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 13.24.55.jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 13.24.49.jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 13.24.13.jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 13.24.03.jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 13.25.12.jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 13.25.41.jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 13.25.27.jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 13.24.42.jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 13.24.38.jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 13.24.58.jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 13.24.16.jpeg\n",
      "Face Detected:  WhatsApp Image 2022-07-26 at 13.25.19.jpeg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# read all images\n",
    "images = []\n",
    "labels = []\n",
    "for i, folder in enumerate(os.listdir(DATASET_PATH)):\n",
    "    SUB_PATH = \"{}/{}\".format(DATASET_PATH, folder)\n",
    "    if os.path.isdir(SUB_PATH):\n",
    "        folders.append(folder)\n",
    "        for image in os.listdir(SUB_PATH):\n",
    "            img = cv2.imread(\"{}/{}\".format(SUB_PATH, image))\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            face = classifier.detectMultiScale(gray, 1.2, 5)\n",
    "            if len(face) > 0:\n",
    "                print(\"Face Detected: \", image)\n",
    "                (x, y, w, h) = face[0]\n",
    "                cropped_image = gray[y:y+h, x:x+w]\n",
    "                images.append(cropped_image)\n",
    "                labels.append(i)\n",
    "                #cv2.imwrite(\"face.jpg\",cropped_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write persons names to labels file\n",
    "with open(\"utils/labels.txt\", 'w') as f:\n",
    "    for i in folders:\n",
    "        f.write(i)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28137/3216828076.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  recognizer.train(np.array(images), np.array(labels))\n"
     ]
    }
   ],
   "source": [
    "recognizer.train(np.array(images), np.array(labels))\n",
    "recognizer.save(\"utils/embeddings.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
