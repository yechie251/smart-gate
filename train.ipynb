{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open embedding file: yechiel_embeddings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:21<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open embedding file: avraham_embeddings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:36<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "face_detection_model = \"models/face_detection_yunet_2022mar.onnx\"\n",
    "top_k = 5000\n",
    "nms_threshold = 0.3\n",
    "score_threshold = 0.9\n",
    "face_recognition_model = \"models/face_recognition_sface_2021dec.onnx\"\n",
    "\n",
    "detector = cv2.FaceDetectorYN.create(face_detection_model,\n",
    "                                    \"\",\n",
    "                                    (320, 320),\n",
    "                                    score_threshold,\n",
    "                                    nms_threshold,\n",
    "                                    top_k)\n",
    "recognizer = cv2.FaceRecognizerSF.create(\n",
    "        face_recognition_model,\"\")\n",
    "\n",
    "\n",
    "\n",
    "path = \"dataset\"\n",
    "\n",
    "# loop over persons in the dataset\n",
    "for folder in os.listdir(path):\n",
    "    print(\"Open embedding file: {}_embeddings.xml\".format(folder))\n",
    "\n",
    "    # open embedding file\n",
    "    f = cv2.FileStorage(\"{}_embeddings.xml\".format(folder), cv2.FileStorage_WRITE)\n",
    "    i = 0\n",
    "    # loop over images and calculate embeddings\n",
    "    for img in tqdm(os.listdir(os.path.join(path, folder))):\n",
    "        image = cv2.imread(os.path.join(path, folder, img))\n",
    "        detector.setInputSize((image.shape[1], image.shape[0]))\n",
    "        try:\n",
    "            faces = detector.detect(image)\n",
    "            face_align = recognizer.alignCrop(image, faces[1][0])\n",
    "            face_feature = recognizer.feature(face_align)\n",
    "            f.write(\"_{}\".format(i), face_feature) #\n",
    "            i+=1\n",
    "        except:\n",
    "            continue\n",
    "    f.release()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save embedings\n",
    "s = cv2.FileStorage(\"embs.xml\", cv2.FileStorage_WRITE)\n",
    "for i in range(5):\n",
    "    s.write(\"_{}\".format(i), face1_feature)\n",
    "s.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read embedings\n",
    "s = cv2.FileStorage(\"embs.xml\", cv2.FileStorage_READ)\n",
    "t = cv2.Mat()\n",
    "for i in range(5):\n",
    "    t.push_back(s.getNode(str(i)).mat())  \n",
    "s.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
